{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98851f24-a2f5-42c6-8435-219764f5af33",
   "metadata": {},
   "source": [
    "  <center><img src=\"images/2024_reInvent_Logo_wDate_Black_V3.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# <a name=\"0\">AWS re:Invent 2024 | Lab 2: Detect, Measure and Remediate hallucinations  </a>\n",
    "## <a name=\"0\">Using Amazon Bedrock Agents for custom intervention when hallucinations are detected </a>\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "In this lab, we will set up our own custom workflow to intervene when hallucinations are detected by using [Amazon Bedrock Agents](https://aws.amazon.com/bedrock/agents/) and route to customer service agents bringing in humans in the loop.\n",
    "\n",
    "\n",
    "##### Notebook Kernel\n",
    "Please choose `Python3` as the kernel type of the top right corner of the notebook if that does not appear by default.\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>This lab auto-cleans up resources to be frugal. </h4>\n",
    "    You can visit this section (<a href=\"#10\"> Clean-up Resources</a>) to change the setting if you need to experiment with prompts and settings. Please run clean-up resources after you are done with experiments. <br/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## Use-Case Overview\n",
    "We want to add our own custom intervention to the RAG powered chatbot we developed in Lab 1.\n",
    "We will be using few of the RAGAS metrics like `answer correctness` and `answer similarity` to develop a custom hallucination score for measuring hallucinations. If the custom hallucination score is less than a custom threshold it indicates that the generated model response is not well aligned with the ground truth. In this situation, we notify a pool of human agents via SNS notification to assist with the query instead of providing the customer with hallucinated model response.\n",
    "\n",
    "\n",
    "To set up this workflow, we leverage AWS services like Amazon Bedrock Agents, Lambdas, Amazon Knowledge Bases as shown in the architecture diagram :\n",
    "\n",
    "The overall workflow involves the following steps as given in the diagram:\n",
    "0. Data Ingestion - S3 raw PDFs ingested to Amazon Knowledge base (we covered this in Lab 1) \n",
    "1. User asks the agent a question relevant to Bedrock User Guide.\n",
    "2. Agent searches for an answer inside the knowledge base.\n",
    "3. The query search goes inside vector database. We are using Opensearch Serverless.\n",
    "4. Relevant answer chunks are retrieved.\n",
    "5. Knowledge base response is generated using `retrieve and generate` api. (covered in lab 1)\n",
    "6. User question and kb response are used to invoke right action group\n",
    "7. User question and kb response are passed as Lambda inputs to calculate hallucination score\n",
    "8. send SNS notification if answer score is lower than the custom threshold (0.9)\n",
    "9. Lambda responds with final KB response if there is no hallucination else sends response that customer agent has been asked to join shortly.\n",
    "10. Final agent response shown to customer UI as elaborated in above step.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"images/lab2-reinvent-arch-diagram-v1.png\" alt=\"This image shows the retrieval augmented generation (RAG) system design setup with knowledge bases, S3, and AOSS. Knowledge corpus is ingested into a vector database using Amazon Bedrock Knowledge Base Agent and then RAG approach is used to work question answering. The question is converted into embeddings followed by semantic similarity search to get similar documents. With the user prompt being augmented with the RAG search response, the LLM is invoked to get the final raw response for the user.\" height=\"700\" width=\"700\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "\n",
    "\n",
    "#### Lab Sections\n",
    "\n",
    "This lab notebook has the following sections:\n",
    "\n",
    "1. <a href=\"#1\">Environment setup and configuration</a>\n",
    "2. <a href=\"#2\">Set up Bedrock for inference</a>\n",
    "3. <a href=\"#3\">Setup agent infrastructure</a>\n",
    "4. <a href=\"#4\">Create an agent</a>\n",
    "5. <a href=\"#5\">Associate knowledge bases, deploy agent, create alias</a>\n",
    "6. <a href=\"#6\">Invoke agent</a>\n",
    "9. <a href=\"#7\">Monitor SNS message count for Human in the Loop setup</a>\n",
    "10. <a href=\"#8\">Clean up resources</a>\n",
    "11. <a href=\"#9\">Challenge exercise and lab quiz</a>\n",
    "    \n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54de30-fe9e-4b38-943a-330065bfa7ef",
   "metadata": {},
   "source": [
    "\n",
    "Let's start by installing all required packages as specified in the `requirements.txt` file and importing several libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463f03b-7f8b-4a95-a7c8-0caa46d6ae4b",
   "metadata": {},
   "source": [
    "\n",
    "## <a name=\"1\">Environment setup and configuration</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Before starting, let's import the required packages and configure the support variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83787e3d-4694-498e-9ecc-7df43bd0cae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5428e2-37d0-4199-a234-33521ec995ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import json\n",
    "import uuid\n",
    "import pprint\n",
    "import os\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from IPython.display import Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from agent_utilities.agents_utils import *\n",
    "from agent_utilities.agents_infra_utils_one_kb_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea10158d-adb7-463e-ae3e-df72da6e850b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=41, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a83780-07e5-48ba-9bea-a20598ee58eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_up_trace_files(\"./trace_files/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84a1f4-9ecb-4e03-a252-7f6fe7832763",
   "metadata": {},
   "source": [
    "### <a name=\"2\">2. Set up Bedrock for inference</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To get started, set up Bedrock and instantiate an active `bedrock-runtime` to query LLMs. The code below leverages [LangChain's Bedrock integration](https://python.langchain.com/docs/integrations/llms/bedrock).\n",
    "```\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "```\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67a917-11f8-43a0-a8d5-1b379ec77119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting boto3 clients for required AWS services\n",
    "bedrock_boto3_config = Config(\n",
    "    connect_timeout=60*10,\n",
    "    read_timeout=60*10,\n",
    ")\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "s3_client = boto3.client('s3')\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "bedrock_agent_client = boto3.client('bedrock-agent', config=bedrock_boto3_config)\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime', config=bedrock_boto3_config)\n",
    "open_search_serverless_client = boto3.client('opensearchserverless', config=bedrock_boto3_config)\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec89861-d8dc-4bef-b4f6-f07a6ff49a2b",
   "metadata": {},
   "source": [
    "### <a name=\"3\">3. Setup agent infrastructure</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "High level workflow:\n",
    "- Setup for variables with various agent resources\n",
    "- Create Lambda function for action group\n",
    "- Create Knowledge Base 1 for QnA with latest the Amazon Bedrock User Guide\n",
    "- Creating an agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1817d01-b93f-4f33-97a1-4ce341c400ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kb_id = None\n",
    "%store -r kb_id\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "print(f\"Lab 1 store kb_id :: {kb_id}\")\n",
    "use_existing_kb = False\n",
    "existing_kb_id = None\n",
    "if kb_id is not None:\n",
    "    use_existing_kb = True\n",
    "    existing_kb_id = kb_id\n",
    "print(f\"use_existing_kb :: {use_existing_kb}\")\n",
    "print(f\"existing_kb_id :: {existing_kb_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ad70a-a52f-48c1-9846-0d41cb67ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_filename='hallucination_agent_openapi_schema_with_kb.json'\n",
    "kb_db_file_uri='kb_hallucination'\n",
    "lambda_code_uri='lambda_hallucination_detection.py'\n",
    "sns_topic_name='reinvent2024_hallucination_lab2b_topic'\n",
    "gt_file_name='reinvent2024-hallucinations-questions.csv'\n",
    "\n",
    "\n",
    "\n",
    "kb_id = None\n",
    "%store -r kb_id\n",
    "# if a kb already exists we can use the same, else the infra setup code will create one by itself using the bedrock user guide.\n",
    "print(f\"Lab 1 store kb_id :: {kb_id}\")\n",
    "if kb_id is not None:\n",
    "    use_existing_kb = True\n",
    "    existing_kb_id = kb_id\n",
    "\n",
    "print(f\"use_existing_kb :: {use_existing_kb}\")\n",
    "print(f\"existing_kb_id :: {existing_kb_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b67872-2702-415b-aba9-3218b1ce884f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# For new KB it takes around ~6 minutes for this setup to complete on a t2.medium instance.\n",
    "infra_response = setup_agent_infrastructure(schema_filename=schema_filename,\n",
    "                                           kb_db_file_uri=kb_db_file_uri,\n",
    "                                           lambda_code_uri=lambda_code_uri,\n",
    "                                           sns_topic_name=sns_topic_name,\n",
    "                                           gt_file_name=gt_file_name,\n",
    "                                           use_existing_kb = use_existing_kb,\n",
    "                                           existing_kb_id = existing_kb_id \n",
    "                                           )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce57f567-607a-4dd2-b9de-014eddf6dafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_name = infra_response[\"agent_name\"]\n",
    "agent_alias_name = infra_response[\"agent_alias_name\"]\n",
    "agent_role = infra_response[\"agent_role\"]\n",
    "bucket_name = infra_response[\"bucket_name\"]\n",
    "schema_key = infra_response[\"schema_key\"]\n",
    "knowledge_base_db_id = infra_response[\"knowledge_base_db_id\"]\n",
    "lambda_name = infra_response[\"lambda_name\"]\n",
    "lambda_function = infra_response[\"lambda_function\"]\n",
    "agent_bedrock_policy = infra_response[\"agent_bedrock_policy\"]\n",
    "agent_s3_schema_policy = infra_response[\"agent_s3_schema_policy\"]\n",
    "agent_role_name = infra_response[\"agent_role_name\"]\n",
    "lambda_role_name = infra_response[\"lambda_role_name\"]\n",
    "kb_db_collection_name = infra_response[\"kb_db_collection_name\"]\n",
    "kb_db_bedrock_policy = infra_response[\"kb_db_bedrock_policy\"]\n",
    "kb_db_aoss_policy = infra_response[\"kb_db_aoss_policy\"]\n",
    "kb_db_s3_policy = infra_response[\"kb_db_s3_policy\"]\n",
    "agent_kb_schema_policy = infra_response[\"agent_kb_schema_policy\"]\n",
    "kb_db_role_name = infra_response[\"kb_db_role_name\"]\n",
    "kb_db_opensearch_collection_response = infra_response[\"kb_db_opensearch_collection_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7647b-20e1-4064-b5bd-93c0e6cb200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66db1f-3f77-4540-9be9-f3bafa6d43a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_base_db_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a0249-e6b4-46d9-aade-c7b006bb22c3",
   "metadata": {},
   "source": [
    "### <a name=\"4\">Create agent</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b86215-bc3d-47f6-a98c-6f96c513d886",
   "metadata": {},
   "source": [
    "\n",
    "Once the needed IAM role is created, we can use the Bedrock agent client to create a new agent. To do so we use the `create_agent` function. It requires an agent name, underline foundation model and instruction. You can also provide an agent description. Note that the agent created is not yet prepared. We will focus on preparing the agent and then using it to invoke actions and use other APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7c63b-6bc0-4b48-a5c0-2db24fa5a21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent_instruction = \"\"\"\n",
    "You are a question answering agent that helps customers answer questions from the Amazon Bedrock User Guide inside the associated knowledge base.\n",
    "Next you will always use the knowledge base search result to detect and measure any hallucination using the functions provided\"\n",
    "\"\"\"\n",
    "# anthropic.claude-3-sonnet-20240229-v1:0\n",
    "# anthropic.claude-3-haiku-20240307-v1:0\n",
    "\n",
    "response = bedrock_agent_client.create_agent(\n",
    "    agentName=agent_name,\n",
    "    agentResourceRoleArn=agent_role['Role']['Arn'],\n",
    "    description=\"Ask questions to get answers from the latest Amazon Bedrock User Guide\",\n",
    "    idleSessionTTLInSeconds=3600,\n",
    "    foundationModel=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    instruction=agent_instruction,\n",
    ")\n",
    "agent_id = response['agent']['agentId']\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89ac0d-b1af-4efa-bbb8-59a8f486a622",
   "metadata": {},
   "source": [
    "Looking at the created agent, we can see its status and agent id. We have saved the `agent_id` in a local variable to use it for the next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b400720-accd-41f7-84f3-c895b2eb3123",
   "metadata": {},
   "source": [
    "### <a name=\"5\">Associate knowledge bases, deploy agent, create alias</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "After we have the agent, we still have to \n",
    "1. Create agent action group\n",
    "2. Allowing agent to invoke action group Lambda\n",
    "3. Associating the agent to the knowledge base\n",
    "4. Prepare the agent\n",
    "5. Create agent alias to deploy agent\n",
    "\n",
    "We cover the implementation inside `setup_agent_after_create()` in `agent_utilties\\agents_infra_utils_one_kb_setup` python file.\n",
    "\n",
    "Once that is done, let's use the `bedrock-agent-runtime` client to invoke this agent and ask user questions on bedrock user guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad4191-b8b0-4245-870f-3b0f3742046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this can take around 2-3 mins \n",
    "agent_alias, agent_action_group_response = setup_agent_after_create(bedrock_agent_client, \n",
    "                                         agent_id,\n",
    "                                         agent_alias_name,\n",
    "                                         lambda_function,\n",
    "                                         bucket_name,\n",
    "                                         schema_key,\n",
    "                                         lambda_name,\n",
    "                                      knowledge_base_db_id,\n",
    "                                        sns_topic_name)\n",
    "#agent_alias_name = agent_alias['agentAlias']['agentAliasName']\n",
    "agent_alias_id = agent_alias['agentAlias']['agentAliasId']\n",
    "print(f\"agent_alias_name :: {agent_alias_name} and agent_alias_id :: {agent_alias_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2844c-04fd-4dfc-a87d-0a668afb8f82",
   "metadata": {},
   "source": [
    "### <a name=\"6\">Invoke agent</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that we've created the agent, let's use the `bedrock-agent-runtime` client to invoke this agent and loop through all user questions inside `reinvent2024-hallucinations-questions.csv` and ask them to the agent.\n",
    "\n",
    "We set the minimum answer score threshold of at least `0.85` for the exact model response to go back to the customer as-is without bringing human in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28360786-bbba-4d31-85cc-3b764ad86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the content of the user-questions and ground truth\n",
    "questions_df = pd.read_csv(\"./reinvent2024-hallucinations-questions.csv\", sep=',')\n",
    "questions_df.style.set_properties(**{'text-align': 'left', 'border': '1px solid black'})\n",
    "questions_df.to_string(justify='left', index=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    pretty_print(questions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b773f7db-6135-4050-a2fa-0bb6779c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = \"\"\"Question: {question}\n",
    "\n",
    "Given an input question, you will search the Knowledge Base on Bedrock User Guide to answer the user question. \n",
    "If the knowledge base search results does not return any answer you can try answering it to the best of your ability but do not answer anything you do not know. Do not hallucinate.\n",
    "Using this knowledge base search results you will ALWAYS execute the appropriate action group API to measure and detect the hallucination on that knowledge base search results.\n",
    "\n",
    "Remove any XML tags from the knowledge base search results and final user response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "agent_answers = list()\n",
    "for index, row in questions_df.iterrows():\n",
    "    session_id = str(uuid.uuid1())\n",
    "    final_agent_answer = None\n",
    "    question_id = row['question_id']\n",
    "    question_text = row['question']\n",
    "    gt_answer = row['ground_truth_answer']\n",
    "    logger.info(f\"-------------Question ID :: {question_id} Question_text :: {question_text} -------------------\")\n",
    "    final_agent_answer = invoke_agent_generate_response(bedrock_agent_runtime_client,\n",
    "                                           USER_PROMPT_TEMPLATE.format(question=question_text),\n",
    "                                           agent_id, \n",
    "                                           agent_alias_id, \n",
    "                                           session_id = session_id, \n",
    "                                           enable_trace = True,\n",
    "                                           end_session = False,\n",
    "                                           trace_filename_prefix = 'lab2_hallucination_agent_trace',\n",
    "                                           turn_number = index)\n",
    "    \n",
    "    time.sleep(5) # to avoid throttling if any\n",
    "    #print(f\"final_agent_answer --> {final_agent_answer}\")\n",
    "    agent_answers.append(final_agent_answer)\n",
    "    format_final_response(question_id = question_id, \n",
    "                          question = question_text, \n",
    "                          final_answer = final_agent_answer, \n",
    "                          lab_number=2, \n",
    "                          turn_number=index, \n",
    "                          show_detailed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbebbe7-f35e-4b4a-ae16-28c29de5ae25",
   "metadata": {},
   "source": [
    "### <a name=\"7\">Monitor the SNS messages received for Human in the Loop setup </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "- To verify the actual SNS message count, you can view the latest  Lambda cloud watch logs following the instructions as given in the [LINK](https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs-view.html) . Search for the string `Received SNS message ::` inside the cloudwatch logs. The lambda function for this notebook is called `LambdaAgentsHallucinationDetection`\n",
    "\n",
    "- To check the SNS message count, you can monitor the number of messages in the SNS topic `reinvent2024_hallucination_lab2b_topic` via cloudwatch metric `NumberOfMessagesPublished` as given in the [LINK](https://docs.aws.amazon.com/sns/latest/dg/sns-monitoring-using-cloudwatch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88211718-0f51-455a-8190-cf4301716579",
   "metadata": {},
   "source": [
    "### <a name=\"8\">[Be Frugal] Clean up resources </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762505dd",
   "metadata": {},
   "source": [
    "##### In the following cell, we offer the option to raise an exception to avoid auto-executing the next block of lines and optionally clean up all resources. This is useful when the `Kernel > run all` option is used.\n",
    "\n",
    "`Please be frugal if you choose to enable this exception in the code cell below. By default it is disabled and all resources will be cleaned up immediately to avoid additional costs.`\n",
    "\n",
    "##### Within the same kernel session, this will allow experimentation with different prompts without having to recreate agent resources (takes ~5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aac2b7-dc28-4122-ab3e-5d3d28abd42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this avoids auto-cleanup\n",
    "raise Exception('Avoiding Auto-Cleanup of Amazon Bedrock Agent Resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60e89e-01e1-410a-822f-b9641dd5150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cleanup_infrastructure(agent_action_group_response, \n",
    "                       lambda_name, \n",
    "                       lambda_function, \n",
    "                       lambda_role_name, \n",
    "                       agent_id, \n",
    "                       agent_alias_id, \n",
    "                       agent_role_name, \n",
    "                       bucket_name, \n",
    "                       schema_key, \n",
    "                       agent_bedrock_policy, \n",
    "                       agent_s3_schema_policy, \n",
    "                       agent_kb_schema_policy, \n",
    "                       kb_db_bedrock_policy, \n",
    "                       kb_db_aoss_policy, \n",
    "                       kb_db_s3_policy, \n",
    "                       kb_db_role_name, \n",
    "                       kb_db_collection_name, \n",
    "                       kb_db_opensearch_collection_response, \n",
    "                       knowledge_base_db_id, \n",
    "                       sns_topic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810acda7-1a6b-4d55-851c-0e29ebe73e40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a name=\"9\">Challenge Exercise :: Try it Yourself! </a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f3d63-c47b-4573-b5b1-8b8f889ad072",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "    <br>\n",
    "    <p style=\"text-align: center; margin: auto;\"><b>Try the following exercises on this lab and note the observations.</b></p>\n",
    "<p style=\" text-align: left; margin: auto;\">\n",
    "<ol>\n",
    " <li>Try a new set of questions to test against the agent, reference the Amazon Bedrock User Guide to come up with these questions. </li>\n",
    "<li> Notice the questions where the human in the loop are getting invoked? Does question reframing/rewriting help avoid it? </li>\n",
    "<li> Try different chunking strategies supported by Bedrock Knowledge base and ask the same set of questions to compare and contrast against each chunking strategy for this use-case. </li>\n",
    "<li> Try additional RAGAS metrics like faithfulness etc. </li>\n",
    "    <li> Try different open source PDF(s) to verify . </li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e11a07-f94a-454d-9d2c-c530c4acbe16",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We now have an understanding of how to detect, measure and remediate hallucinations with Human in the Loop even after applying RAG workflows with an agentic AI workflow. \n",
    "Furthermore, each failure scenario could be an opportunity to improve the raw datasource for better clarity.\n",
    "\n",
    "\n",
    "### Take aways \n",
    "- Adapt this notebook to create newer hallucination detection and thresholding mechanisms to involve human in the loop for your use-case.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
