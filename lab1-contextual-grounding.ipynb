{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e124503b",
   "metadata": {},
   "source": [
    "# <a id=\"top\">Lab 1: Contextual Grounding with Agentic AI Tools</a>\n",
    "## Mitigating Hallucinations Through RAG and Bedrock Guardrails\n",
    "\n",
    "In this notebook, we will explore how to reduce LLM hallucinations using **Retrieval-Augmented Generation (RAG)** and **AWS Bedrock Guardrails**. We'll demonstrate how providing relevant context to LLMs and validating their outputs can significantly improve factual accuracy - and how the RAG pattern relates to more general tool use in **AI Agents**.\n",
    "\n",
    "##### Notebook Kernel\n",
    "Please choose `Python3` as the kernel type at the top right corner of the notebook if that does not appear by default.\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px\">\n",
    "    <h4>üí° Key Learning Objectives</h4>\n",
    "    <ul>\n",
    "        <li>Understand why LLMs hallucinate without proper context</li>\n",
    "        <li>Learn how RAG (Retrieval-Augmented Generation) reduces hallucinations</li>\n",
    "        <li>Integrate MCP (Model Context Protocol) servers with Strands agents</li>\n",
    "        <li>Configure AWS Bedrock Guardrails for contextual grounding checks</li>\n",
    "        <li>Build production-ready agents with automatic hallucination detection</li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "## Use-Case Overview\n",
    "\n",
    "**The Problem:** LLMs are trained on static data and cannot access real-time or proprietary information. When asked about specific details they don't know, they often \"hallucinate\" plausible-sounding but incorrect answers.\n",
    "\n",
    "**The Solution:** By combining:\n",
    "- **RAG (Retrieval-Augmented Generation)**: Provide relevant context from authoritative sources\n",
    "- **Contextual Grounding Checks**: Validate that responses are supported by the provided context\n",
    "\n",
    "We can dramatically reduce hallucinations and improve factual accuracy.\n",
    "\n",
    "\n",
    "## Sections\n",
    "\n",
    "This notebook has the following sections:\n",
    "\n",
    "1. [Dependencies and Setup](#1.-Dependencies-and-Setup)\n",
    "2. [Baseline: LLMs Without Context (Hallucinations)](#2.-Baseline:-LLMs-Without-Context-(Hallucinations))\n",
    "3. [RAG Helps: Adding Context with MCP Servers](#3.-RAG-Helps:-Adding-Context-with-MCP-Servers)\n",
    "4. [Bedrock Guardrails: Contextual Grounding Validation](#4.-Bedrock-Guardrails:-Contextual-Grounding-Validation)\n",
    "5. [Production Integration: Agents with Automatic Detection](#5.-Production-Integration:-Agents-with-Automatic-Detection)\n",
    "6. [Conclusion and Best Practices](#6.-Conclusion-and-Best-Practices)\n",
    "\n",
    "Please work from top to bottom and don't skip sections as this could lead to error messages due to missing dependencies.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1d86b",
   "metadata": {},
   "source": [
    "## 1. Dependencies and Setup\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "**If you haven't already** installed the workshop's dependencies (from [pyproject.toml](./pyproject.toml)), you can un-comment (remove `# `) and run the below cell to do so. We've commented it out by default, assuming you already ran it at the start of lab 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1174a-c7c1-452d-bca1-69c9b6bed7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e8e4e",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px; padding-top: 15px;\">\n",
    "    <h4>üîÑ Restart the kernel after installing</h4>\n",
    "    <p>\n",
    "        <strong>IF</strong> you ran the above install command cell, you'll need to restart the\n",
    "        notebook kernel afterwards for the installations to take full effect.\n",
    "    </p>\n",
    "    <p>\n",
    "        Note that you may see some error notices about dependency conflicts in SageMaker Studio\n",
    "        environments, but this is okay as long as the installations are completed.\n",
    "    </p>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "With the installation complete, you're ready to import the libraries we'll use in the notebook and set up some basic configurations including:\n",
    "\n",
    "- **Langfuse:** See the [\"Getting started\" section](https://catalog.us-east-1.prod.workshops.aws/workshops/1fa309f2-c771-42d5-87bc-e8f919e7bcc9/en-US/10-setup/03-langfuse) of the accompanying workshop guide for how to find your Langfuse keys and host name\n",
    "    - If you chose not to set up Langfuse, you can ignore the error here or comment-out the `set_up_notebook_langfuse()` call\n",
    "- **Model:** We'll use an API-based foundation model on Amazon Bedrock for this lab.\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** To avoid re-prompting you after every notebook or kernel restart, the `set_up_notebook_langfuse()` utility will store your Langfuse credentials **unencrypted** in a local file called `.env` (hidden in JupyterLab folder explorer, but visible and deletable via the terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77575bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from mcp import StdioServerParameters, stdio_client\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from strands import Agent\n",
    "from strands.types.exceptions import EventLoopException\n",
    "from strands.models.bedrock import BedrockModel\n",
    "from strands.tools.mcp import MCPClient\n",
    "from strands_tools import calculator\n",
    "\n",
    "# Local Dependencies:\n",
    "from hallucination_utils.bedrock_guardrails import (\n",
    "    BedrockGuardrailHook,\n",
    "    GuardrailFailedError,\n",
    ")\n",
    "from hallucination_utils.mcp import get_aws_mcp_env, mcp_all_tools\n",
    "from hallucination_utils.tracing import set_up_notebook_langfuse\n",
    "\n",
    "set_up_notebook_langfuse(\n",
    "    ## Un-comment the below to force asking for the credentials again:\n",
    "    # refresh=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BedrockModel(\n",
    "    model_id=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1d96d",
   "metadata": {},
   "source": [
    "## 2. Baseline: LLMs Without Context (Hallucinations)\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "First, let's demonstrate an example of hallucination when an LLM is asked a question without access to external knowledge. We'll create a basic agent and ask it a specific question about AWS SageMaker that requires up-to-date documentation.\n",
    "\n",
    "**Desired Behavior**: The correct answer to the below question is **v2.98.0+** as stated on [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html).\n",
    "\n",
    "**Expected Hallucination**: The model should here provide a plausible-sounding but incorrect answer because it lacks access to the specific documentation needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ea3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What version of SageMaker SDK do I need to start heterogeneous training jobs?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225594ca",
   "metadata": {},
   "source": [
    "## 3. RAG Helps: Adding Context with MCP Servers\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "In this section, you'll build an intelligent agent using the [Strands Agents SDK](https://strandsagents.com/latest/) (an open-source framework for building agentic AI applications) and [Model Context Protocol (MCP)](https://modelcontextprotocol.io/docs/getting-started/intro).\n",
    "\n",
    "> **Note**: This lab covers contextual grounding using MCP tool outputs as reference sources. Lab 4 (optional) demonstrates traditional RAG-based contextual grounding using Amazon Bedrock Knowledge Bases.\n",
    "\n",
    "### Understanding RAG\n",
    "\n",
    "[Retrieval-Augmented Generation (RAG)](https://aws.amazon.com/what-is/retrieval-augmented-generation/) reduces LLM hallucinations by grounding responses in trusted sources. Instead of relying solely on the model's training data, we:\n",
    "\n",
    "1. **Retrieve** relevant documents from a knowledge base based on the user's query\n",
    "2. **Augment** the LLM prompt with retrieved context alongside the original question\n",
    "3. **Generate** an answer grounded in the provided sources\n",
    "\n",
    "Traditional RAG requires building and maintaining a static knowledge base through data ingestion pipelines, vectorization, and indexing.\n",
    "\n",
    "### Why MCP over Traditional RAG?\n",
    "\n",
    "MCP extends the RAG pattern with dynamic, standardized tool access:\n",
    "\n",
    "- **Zero setup**: Pre-built tools (e.g., AWS Documentation MCP) work immediately‚Äîno ingestion pipeline required\n",
    "- **Live data**: Real-time access to APIs and documentation vs. static snapshots\n",
    "- **Broader ecosystem**: Beyond documents‚ÄîAPIs, databases, calculators, and custom tools\n",
    "- **Dynamic routing**: The LLM selects which tools to invoke based on the query\n",
    "\n",
    "### MCP as a Standard\n",
    "\n",
    "[MCP](https://modelcontextprotocol.io/docs/getting-started/intro) provides a standardized interface for [AI Agents](https://aws.amazon.com/what-is/ai-agents/) to connect with multiple knowledge sources and APIs, enabling tool reusability across different agent frameworks.\n",
    "\n",
    "---\n",
    "\n",
    "Below, let's connect our agent to real-time AWS Documentation search using the [AWS Documentation MCP Server from AWSLabs](https://github.com/awslabs/mcp). With this access, the agent should be able to look up the correct **v2.98.0+** answer and reflect that in its response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4732a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_docs_mcp = MCPClient(\n",
    "    lambda: streamablehttp_client(url=\"https://knowledge-mcp.global.api.aws\")\n",
    ")\n",
    "\n",
    "with mcp_all_tools(aws_docs_mcp) as tools:\n",
    "    rag_agent = Agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "    )\n",
    "    rag_agent(\n",
    "        \"What version of SageMaker SDK do I need to start heterogeneous training jobs?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e064f4f",
   "metadata": {},
   "source": [
    "### RAG Improves Accuracy, But Isn't Perfect\n",
    "\n",
    "While RAG significantly reduces hallucinations, errors can still occur:\n",
    "\n",
    "- **Relevance Issues**: The agent might retrieve relevant content but generate an answer that doesn't actually address the user's specific question\n",
    "- **Grounding Issues**: The agent might generate claims that aren't fully supported by the retrieved documentation\n",
    "\n",
    "Let's consider a more complex query:\n",
    "\n",
    "> *\"By default, Can an AgentCore agent have more aliases than I can count on one hand?\"*\n",
    "\n",
    "By default at the time of writing, this limit is 10 as documented [here in the Developer Guide](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/bedrock-agentcore-limits.html#runtime-service-limits). The model and agent we're using will generally give a confident \"yes\" based on an **assumption** that you, the user, can count to exactly 5 on one hand - predicated on you having four fingers and a thumb, and you **not** being familiar with alternative systems that can count to 10 or more (like [Chinese](https://en.wikipedia.org/wiki/Chinese_number_gestures) or [other systems](https://en.wikipedia.org/wiki/Finger-counting#By_country_or_region)).\n",
    "\n",
    "These assumptions may be reasonable for many contexts, but still provides a basic toy example for ways that vagueness or assumed external knowledge in the question can re-introduce risk of hallucination issues in Retrieval-Augmented systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c26332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mcp_all_tools(aws_docs_mcp) as tools:\n",
    "    rag_agent = Agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "    )\n",
    "    rag_agent(\"By default, Can an AgentCore agent have more aliases than I can count on one hand?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b46579",
   "metadata": {},
   "source": [
    "## 4. Bedrock Guardrails: Contextual Grounding Validation\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "While MCP tools provide rich information access, we need to ensure responses remain factually grounded and relevant. To address the remaining accuracy issues, you'll implement Amazon Bedrock Guardrails with contextual grounding checks that validate against tool-provided context.\n",
    "\n",
    "### Contextual Grounding Beyond Traditional RAG\n",
    "\n",
    "Contextual grounding extends beyond static document retrieval:\n",
    "\n",
    "- **Tool-based grounding**: Use information retrieved by MCP tools as grounding sources\n",
    "- **Multi-source validation**: Combine multiple tool outputs for comprehensive grounding\n",
    "- **Dynamic context**: Grounding sources change based on which tools the agent invokes\n",
    "- **Real-time validation**: Ensure responses reflect the most current information\n",
    "\n",
    "### How Bedrock Guardrails Works\n",
    "\n",
    "Amazon Bedrock Guardrails validates responses across two dimensions:\n",
    "\n",
    "1. **Grounding**: The model's response is factually supported by tool-provided information\n",
    "2. **Relevance**: The response directly addresses the user's query\n",
    "\n",
    "Guardrails analyzes both the retrieved context and the model's response, assigning confidence scores for each dimension. If either score falls below your configured threshold, the guardrail blocks the response.\n",
    "\n",
    "---\n",
    "\n",
    "Let's create a guardrail with contextual grounding enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23305de",
   "metadata": {},
   "outputs": [],
   "source": [
    "guardrail_name = \"context-guardrail\"\n",
    "print(f\"guardrail_name: {guardrail_name}\")\n",
    "\n",
    "bedrock = boto3.client(\"bedrock\")\n",
    "try:\n",
    "    create_guardrail_resp = bedrock.create_guardrail(\n",
    "        name=guardrail_name,\n",
    "        description=\"Guardrail for AWS assistant with contextual grounding\",\n",
    "        contextualGroundingPolicyConfig={\n",
    "            \"filtersConfig\": [\n",
    "                {\n",
    "                    \"type\": \"GROUNDING\",\n",
    "                    \"threshold\": 0.8,  # 80% confidence threshold for grounding\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"RELEVANCE\",\n",
    "                    \"threshold\": 0.8,  # 80% confidence threshold for relevance\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        blockedInputMessaging=\"Sorry I cannot help with this request. Please ask a question about AWS\",\n",
    "        blockedOutputsMessaging=\"Sorry, I wasn't able to generate you a confident answer on this topic.\",\n",
    "    )\n",
    "\n",
    "    guardrail_id = create_guardrail_resp[\"guardrailId\"]\n",
    "    guardrail_version = create_guardrail_resp[\"version\"]\n",
    "\n",
    "    print(f\"‚úì Created guardrail ID: {guardrail_id}\")\n",
    "\n",
    "    ## Note that you can version-control your guardrails, but for the purposes of this workshop\n",
    "    ## we'll skip that:\n",
    "    # version_response = bedrock.create_guardrail_version(\n",
    "    #     guardrailIdentifier=guardrail_id,\n",
    "    #     description=\"Initial version with contextual grounding\"\n",
    "    # )\n",
    "    # guardrail_version = version_response['version']\n",
    "    guardrail_version = \"DRAFT\"\n",
    "\n",
    "except bedrock.exceptions.ConflictException as e:\n",
    "    found = False\n",
    "    for page in bedrock.get_paginator(\"list_guardrails\").paginate():\n",
    "        for guardrail in page[\"guardrails\"]:\n",
    "            if guardrail[\"name\"] == guardrail_name:\n",
    "                found = True\n",
    "                guardrail_id = guardrail[\"id\"]\n",
    "                guardrail_version = \"DRAFT\"\n",
    "                print(f\"WARNING - Pre-existing guardrail ID {guardrail_id}\")\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    if not found:\n",
    "        raise ValueError(\n",
    "            \"Got ConflictExpression but couldn't find matching guardrail\"\n",
    "        ) from e\n",
    "\n",
    "print(f\"‚úì Using guardrail version: {guardrail_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162a43f",
   "metadata": {},
   "source": [
    "You can also find your created guardrail and explore other configuration options in the [AWS Console for Amazon Bedrock Guardrails](https://console.aws.amazon.com/bedrock/home?#/guardrails).\n",
    "\n",
    "## 5. Production Integration: Agents with Automatic Detection\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "In this section, you'll integrate guardrails with Strands agents using custom hooks. Since direct BedrockModel-based integration doesn't work with all agent frameworks, you'll implement wrapper patterns that apply contextual grounding checks to tool outputs.\n",
    "\n",
    "### Custom Integration Approach\n",
    "\n",
    "We've created a custom [Strands Hook](https://strandsagents.com/latest/documentation/docs/api-reference/hooks/#) (callback) implementation that:\n",
    "\n",
    "- **Wraps agent responses**: Intercepts responses before they reach the user\n",
    "- **Applies contextual grounding**: Uses MCP tool outputs as grounding sources for validation\n",
    "- **Validates concurrently**: Checks both grounding and relevance against configured thresholds\n",
    "- **Blocks hallucinations**: Raises an exception if either check fails, preventing ungrounded responses from reaching users\n",
    "\n",
    "You can explore the implementation in the [`hallucination_utils`](./hallucination_utils) folder.\n",
    "\n",
    "### Practical Implementation\n",
    "\n",
    "You'll build an agent that:\n",
    "\n",
    "1. **Configures AWS Documentation MCP server** for immediate use without ingestion\n",
    "2. **Answers AWS questions** using live documentation via MCP tools\n",
    "3. **Validates responses** with contextual grounding checks using tool outputs as reference sources\n",
    "4. **Tests and optimizes** grounding and relevance thresholds across various query types\n",
    "\n",
    "If our agent generates a response that fails the grounding or relevance checks, the guardrail will raise an exception - preventing the hallucinated response from reaching the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2914fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mcp_all_tools(aws_docs_mcp) as tools:\n",
    "    guarded_agent = Agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        hooks=[\n",
    "            BedrockGuardrailHook(\n",
    "                guardrail_id=guardrail_id,\n",
    "                guardrail_version=guardrail_version,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        guarded_agent(\"By default, Can an AgentCore agent have more aliases than I can count on one hand?\")\n",
    "    except (GuardrailFailedError, EventLoopException) as e:\n",
    "        e_original = getattr(e, \"original_exception\", e)\n",
    "        if not isinstance(e_original, GuardrailFailedError):\n",
    "            raise e  # Some other EventLoopException not caused by Guardrail\n",
    "        print(\"Guardrail intervened!\")\n",
    "        print(e_original.guardrail_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9266bc9-1c26-451c-a3b0-82dede2395f9",
   "metadata": {},
   "source": [
    "Because we set the guardrail thresholds quite high, you should see the guardrail intervene in this example - usually due to `GROUNDING` because of the external assumptions introduced by the question.\n",
    "\n",
    "If you've enabled Langfuse tracing, you can open up the most recent trace in the Langfuse UI to further explore the detailed findings of the Bedrock Guardrail API operation that intervened in the generation, as shown below. In this case, we've set up our hook to log the full details provided by the [Bedrock ApplyGuardrail API](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-use-independent-api.html).\n",
    "\n",
    "![](./img/langfuse-lab1.png \"Screenshot of Langfuse web UI showing the details of a recorded trace. After an initial event loop cycle, the agent has errored due to Bedrock Guardrail intervening. In the span details pane on the right hand side, additional details of the Bedrock ApplyGuardrail API response are available\")\n",
    "\n",
    "You can also refer to the messages history of the agent, which does *not* include the final output message that triggered the guardrail intervention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "guarded_agent.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b4b79",
   "metadata": {},
   "source": [
    "üéØ **A small challenge:** Can you think of any other example questions to illustrate this guardrail in action? Some scenarios to explore could include:\n",
    "- Distraction to produce **irrelevant** responses by questions that *seem* to overlap with material from the AWS documentation (due to similar names, etc), but were actually asking about something else\n",
    "- Causing **ungrounded** responses by asking to relate AWS information to other details that are *not* in the documentation visible to the agent - like general world knowledge, out-of-scope technologies, or even competitor services?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54b15b",
   "metadata": {},
   "source": [
    "## 6. Conclusion and Best Practices\n",
    "(<a href=\"#top\">Go to top</a>)\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In situations where trusted source data is available, inserting relevant content into the input prompt greatly reduces the likelihood of LLM hallucinations. This \"Retrieval-Augmented Generation\" pattern can be used in deterministic flows, but also applied to AI Agents which might work with multiple knowledge repositories or other API tools and decide when to call each one.\n",
    "\n",
    "However, **RAG isn't perfect**: Our knowledgebase might not contain relevant information to answer a question, or the wording of the content or question could make it difficult for search engines to retrieve the necessary data. In these cases:\n",
    "1. The LLM might generate answers that are **irrelevant** to the user's actual question - distracted by irrelevant search results\n",
    "2. We might still generate **ungrounded** answers that aren't fully faithful to the source content - especially if its relationship to the question is complex.\n",
    "\n",
    "To address these risks, contextual grounding checks like those provided in Amazon Bedrock Guardrails provide an extra layer of safety for high-performing RAG-like systems - including AI Agents and MCP.\n",
    "\n",
    "\n",
    "### Best Practices for Production\n",
    "\n",
    "When building production agents with hallucination mitigation:\n",
    "\n",
    "- ‚úÖ **Always use RAG** for domain-specific or up-to-date information\n",
    "- ‚úÖ **Add guardrails** for high-stakes applications where accuracy is critical\n",
    "- ‚úÖ **Configure appropriate thresholds** based on your use case (stricter for medical/legal, more relaxed for general queries)\n",
    "- ‚úÖ **Monitor guardrail interventions** to identify areas where your knowledge base may need improvement\n",
    "- ‚úÖ **Provide fallback responses** when guardrails block a response, guiding users on how to rephrase their query\n",
    "\n",
    "### Additional Guardrail Features\n",
    "\n",
    "Beyond contextual grounding, AWS Bedrock Guardrails also support:\n",
    "- **Content filtering**: Block harmful, inappropriate, or sensitive content\n",
    "- **PII detection**: Prevent leakage of personally identifiable information\n",
    "- **Topic blocking**: Restrict conversations to approved topics\n",
    "- **Custom word filters**: Block specific terms or phrases\n",
    "\n",
    "Explore the [Bedrock Guardrails documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html) to learn more about these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
